"use client";

import { useState, useEffect, useRef } from "react";
import SpeechRecognition, {
  useSpeechRecognition,
} from "react-speech-recognition";
import { motion } from "framer-motion";
import Confetti from "react-confetti";
import { useRouter } from "next/navigation";

export default function Level8() {
  const [callActive, setCallActive] = useState(false);
  const [muted, setMuted] = useState(false);
  const [timeLeft, setTimeLeft] = useState(10);
  const [aiReply, setAiReply] = useState("");
  const [conversationHistory, setConversationHistory] = useState<any[]>([]);
  const [showCompletion, setShowCompletion] = useState(false);
  const [showConfetti, setShowConfetti] = useState(false);
  const {
    transcript = "",
    resetTranscript,
    listening,
  } = useSpeechRecognition();

  const isProcessingRef = useRef(false);
  const audioQueueRef = useRef<HTMLAudioElement[]>([]);
  const router = useRouter();

  // âœ… Load completion state from localStorage
  useEffect(() => {
    const completed = localStorage.getItem("level8Completed") === "true";
    if (completed) {
      setShowCompletion(true);
    }
  }, []);

  // ğŸ”Š Start/Stop call
  const toggleCall = async () => {
    if (callActive) {
      endCall();
    } else {
      if (!SpeechRecognition.browserSupportsSpeechRecognition()) {
        alert(
          "Your browser does not support speech recognition. Please use Chrome."
        );
        return;
      }
      const permissionGranted = await getMicPermission();
      if (!permissionGranted) return;

      setCallActive(true);
      setTimeLeft(10);
      setConversationHistory([]);
      SpeechRecognition.startListening({ continuous: true, language: "en-US" });

      const greeting = "911, what's your emergency?";
      handleAiReply(greeting);
      setConversationHistory([{ role: "assistant", content: greeting }]);
    }
  };

  const endCall = () => {
    setCallActive(false);
    SpeechRecognition.stopListening();
    resetTranscript();
  };

  // ğŸ¤ Restart listening if dropped
  useEffect(() => {
    if (callActive && !listening) {
      SpeechRecognition.startListening({ continuous: true, language: "en-US" });
    }
  }, [listening, callActive]);

  // ğŸ•’ Timer
  useEffect(() => {
    if (!callActive) return;
    if (timeLeft <= 0) {
      handleCompletion();
      return;
    }
    const interval = setInterval(() => setTimeLeft((t) => t - 1), 1000);
    return () => clearInterval(interval);
  }, [callActive, timeLeft]);

  // âœ… Completion handler
  const handleCompletion = () => {
    const completedBefore = localStorage.getItem("level8Completed") === "true";

    if (!completedBefore) {
      setShowConfetti(true);
      setTimeout(() => setShowConfetti(false), 5000);
      localStorage.setItem("level8Completed", "true");
    }

    setShowCompletion(true);
    endCall();
  };

  // ğŸ™ï¸ When user stops talking
  useEffect(() => {
    if (!callActive || listening || !transcript.trim()) return;
    processUserInput(transcript.trim());
    resetTranscript();
  }, [listening, transcript]);

  const getMicPermission = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      stream.getTracks().forEach((track) => track.stop());
      return true;
    } catch (err) {
      console.error("Mic denied:", err);
      alert("Microphone access is required.");
      return false;
    }
  };

  const processUserInput = async (text: string) => {
    if (isProcessingRef.current) return;
    isProcessingRef.current = true;

    setConversationHistory((prev) => [
      ...prev,
      { role: "user", content: text },
    ]);

    try {
      const res = await fetch("/api/level8/respond", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          transcript: text,
          conversationHistory: [
            ...conversationHistory,
            { role: "user", content: text },
          ],
        }),
      });

      const data = await res.json();
      if (data.reply) {
        setConversationHistory((prev) => [
          ...prev,
          { role: "assistant", content: data.reply },
        ]);
        handleAiReply(data.reply);
      }
    } catch (err) {
      console.error("Error sending to /respond:", err);
    } finally {
      isProcessingRef.current = false;
    }
  };

  const handleAiReply = async (text: string) => {
    setAiReply(text);
    try {
      const res = await fetch("/api/level8/tts", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text }),
      });

      const blob = await res.blob();
      const url = URL.createObjectURL(blob);
      const audio = new Audio(url);

      audio.onended = () => {
        audioQueueRef.current.shift();
        if (audioQueueRef.current.length > 0) {
          audioQueueRef.current[0].play();
        }
      };

      audioQueueRef.current.push(audio);
      if (audioQueueRef.current.length === 1 && !muted) {
        audio.play();
      }
    } catch (err) {
      console.error("TTS error:", err);
    }
  };

  const handleMuteAndSend = () => {
    if (transcript.trim()) processUserInput(transcript.trim());
    resetTranscript();

    if (!muted) {
      SpeechRecognition.stopListening();
    } else {
      SpeechRecognition.startListening({ continuous: true, language: "en-US" });
    }
    setMuted((prev) => !prev);
  };
  // ================= RETURN ==================
  return (
    <div className="relative w-full min-h-screen  text-white">
      {showCompletion ? (
        <div
          className="relative z-10 w-full min-h-screen flex flex-col justify-center items-center text-center px-4 py-10 sm:py-20 bg-cover bg-center bg-no-repeat animate__animated animate__fadeInUp"
          style={{
            backgroundImage:
              "url('https://cdn.prod.website-files.com/61a05ff14c09ecacc06eec05/6720e94e1cd203b14c045522_%20Interview-Notes.jpg')",
          }}
        >
          {/* Dark overlay */}
          <div className="absolute inset-0 bg-black/80 z-0"></div>

          {/* Confetti */}
          <Confetti className="w-full h-full z-10" />

          {/* Content */}
          <div className="relative z-20 max-w-2xl w-full px-4">
            <h2 className="text-2xl sm:text-4xl font-bold text-green-400 mb-4">
              ğŸ‰ Conversation Completed!
            </h2>
            <p className="text-sm sm:text-lg text-white mb-6">
              Great job! Youâ€™ve finished Level 4. Please sign up to know your
              score. ğŸ˜
            </p>
            <button
              className="px-6 py-3 bg-white text-black font-semibold rounded-full transition duration-300 shadow-lg hover:bg-violet-500 hover:text-white"
              onClick={() => router.push("/")}
            >
              End
            </button>
          </div>
        </div>
      ) : (
<>
  <div  className="flex flex-col items-center justify-center min-h-screen gap-8 text-white relative overflow-hidden font-mono"
  style={{
    backgroundImage:
      'url("/emergency-911.jpg")',
    backgroundSize: 'cover',
    backgroundPosition: 'center',
  }}>
    {/* ğŸš¨ Animated siren background */}
    <div className="absolute inset-0 z-0 animate-backgroundPulse bg-[linear-gradient(270deg,_#dc2626,_#4f46e5,_#dc2626)] bg-[length:600%_600%] opacity-100 mix-blend-overlay"></div>

    {/* ğŸš” Glassmorphism container */}
    <div className="relative z-10 backdrop-blur-xl bg-white/10 border-2 border-white/20 shadow-[0_0_60px_rgba(255,0,0,0.4)] rounded-3xl p-8 max-w-2xl w-[90%] flex flex-col gap-6 items-center justify-center transition-all duration-500">

      {/* â± Timer */}
      <motion.div
        initial={{ scale: 0.8, opacity: 0 }}
        animate={{ scale: 1, opacity: 1 }}
        className="text-md sm:text-3xl font-bold tracking-widest text-white"
      >
        â± Time Left:{" "}
        <span className={timeLeft < 10 ? "text-red-400 animate-pulse" : "text-green-400"}>
          {timeLeft}s
        </span>
      </motion.div>

      {/* ğŸ’¬ AI Reply */}
      <motion.div
        initial={{ y: -20, opacity: 0 }}
        animate={{ y: 0, opacity: 1 }}
        className="p-6 rounded-xl bg-gradient-to-br from-red-900 to-blue-900 border border-white/30 shadow-xl text-white text-center w-full"
      >
        {aiReply ? (
          <p className="text-lg font-medium leading-relaxed">{aiReply}</p>
        ) : (
          <p className="italic text-gray-300">Dispatcher is waiting...</p>
        )}
      </motion.div>

      {/* ğŸ™ï¸ Listening indicator */}
      <div className="flex items-center gap-3 text-lg text-white">
        <div
          className={`w-4 h-4 rounded-full border-2 border-white ${
            listening ? "bg-green-400 animate-ping" : "bg-red-600"
          }`}
        />
        <span>ğŸ™ï¸ Listening: {listening ? "âœ… Yes" : "âŒ No"}</span>
      </div>

      {/* ğŸ“ Transcript */}
      <div className="text-gray-200 text-sm italic text-center max-w-md">
        {transcript ? `"${transcript}"` : "You can speak now..."}
      </div>

      {/* ğŸ”˜ Buttons */}
      <div className="flex gap-4 w-full justify-center">
        <button
          onClick={toggleCall}
          className="px-6 py-3 bg-gradient-to-br from-red-600 to-red-800 hover:from-red-700 hover:to-red-900 text-white font-bold rounded-xl shadow-md transition transform hover:scale-105 duration-300"
        >
          {callActive ? "ğŸš¨ End Call" : "ğŸ“ Start Emergency Call"}
        </button>

        {callActive && (
          <button
            onClick={handleMuteAndSend}
            className="px-6 py-3 bg-gradient-to-br from-gray-600 to-gray-800 hover:from-gray-700 hover:to-gray-900 text-white font-semibold rounded-xl shadow-md transition transform hover:scale-105 duration-300"
          >
            {muted ? "ğŸ”Š Unmute" : "ğŸ”‡ Mute & Send"}
          </button>
        )}
      </div>
    </div>
  </div>

  {/* ğŸŒˆ Add style inside your component */}
  <style jsx>{`
    @keyframes backgroundPulse {
      0% {
        background-position: 0% 50%;
      }
      50% {
        background-position: 100% 50%;
      }
      100% {
        background-position: 0% 50%;
      }
    }

    .animate-backgroundPulse {
      animation: backgroundPulse 6s ease-in-out infinite;
    }
  `}</style>
</>

      )}
    </div>
  );
}
